{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Deep Learning - Word2Vec and Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "o4LjQBf8XHJq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cheng\\Anaconda3\\lib\\site-packages\\tqdm\\std.py:658: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n",
      "C:\\Users\\cheng\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas(desc=\"progress-bar\")\n",
    "from gensim.models import Doc2Vec\n",
    "from sklearn import utils\n",
    "import gensim\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from pandas import Panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SGJ-L8tdX5SA"
   },
   "outputs": [],
   "source": [
    "movie_cleaned = pd.read_csv('../IMDB/movie_cleaned.csv')\n",
    "review_cleaned = pd.read_csv('../IMDB/review_cleaned.csv')\n",
    "movie_title_cleaned = pd.read_csv('../IMDB/movie_titles_cleaned.csv')\n",
    "data = pd.merge(review_cleaned, movie_cleaned, on='movie_id')\n",
    "df = pd.merge(data, movie_title_cleaned, on='movie_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mfFwnv782Aur"
   },
   "outputs": [],
   "source": [
    "def confusion_table(test_y, pred_y):\n",
    "    tn, fp, fn, tp = confusion_matrix(test_y, pred_y).ravel()\n",
    "    cm = pd.DataFrame(columns=['Predicted Negative','Predicted Positive'], index=['Actual Negative', 'Actual Positive'])\n",
    "    cm['Predicted Positive'][1] = tp\n",
    "    cm['Predicted Positive'][0] = fp\n",
    "    cm['Predicted Negative'][1] = fn\n",
    "    cm['Predicted Negative'][0] = tn\n",
    "    \n",
    "    print(\"True Negatives: %s\" % tn)\n",
    "    print(\"False Negatives: %s\" % fn)\n",
    "    print(\"False Positives: %s\" % fp)\n",
    "    print(\"True Positives: %s\" % tp)\n",
    "    return cm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec on one movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VrZ2_oMbYmNY"
   },
   "outputs": [],
   "source": [
    "list_movies = list(df['movie_title'].value_counts()[:1].index)\n",
    "one_movie = df[df['movie_title'].isin(list_movies)]\n",
    "one_movie = one_movie[['review', 'is_spoiler']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iFac1FJgeTpy"
   },
   "outputs": [],
   "source": [
    "train_data, test_data = train_test_split(one_movie, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "OgdtvaGQeTvq",
    "outputId": "12c2ad08-4d53-437e-b152-bf0339590dd3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"../IMDB/GoogleNews-vectors-negative300.bin.gz\", binary=True)\n",
    "wv.init_sims(replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uyjVl1oqeTsp"
   },
   "outputs": [],
   "source": [
    "def word_averaging(wv, words):\n",
    "    all_words, mean = set(), []\n",
    "    \n",
    "    for word in words:\n",
    "        if isinstance(word, np.ndarray):\n",
    "            mean.append(word)\n",
    "        elif word in wv.vocab:\n",
    "            mean.append(wv.vectors_norm[wv.vocab[word].index])\n",
    "            all_words.add(wv.vocab[word].index)\n",
    "\n",
    "    if not mean:\n",
    "        logging.warning(\"cannot compute similarity with no input %s\", words)\n",
    "        return np.zeros(wv.layer1_size,)\n",
    "\n",
    "    mean = gensim.matutils.unitvec(np.array(mean).mean(axis=0)).astype(np.float32)\n",
    "    return mean\n",
    "\n",
    "def  word_averaging_list(wv, text_list):\n",
    "    return np.vstack([word_averaging(wv, review) for review in text_list ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pxx4aPlNeTnJ"
   },
   "outputs": [],
   "source": [
    "def w2v_tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text, language='english'):\n",
    "        for word in nltk.word_tokenize(sent, language='english'):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(word)\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcAyfktJeTkm"
   },
   "outputs": [],
   "source": [
    "test_tokenized = test_data.apply(lambda r: w2v_tokenize_text(r['review']), axis=1).values\n",
    "train_tokenized = train_data.apply(lambda r: w2v_tokenize_text(r['review']), axis=1).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "HKpXEw51hqXs",
    "outputId": "04a092f9-fbd7-4efc-8e45-2a50dacee744"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6.37 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_word_average = word_averaging_list(wv,train_tokenized)\n",
    "X_test_word_average = word_averaging_list(wv,test_tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "xjtSWEwynlKM",
    "outputId": "5060ed7f-bbd4-4c20-a54b-f5da9345d957"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['My',\n",
       " 'favorite',\n",
       " 'superhero',\n",
       " 'movie',\n",
       " 'One',\n",
       " 'of',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'movies',\n",
       " 'ever',\n",
       " 'and',\n",
       " 'my',\n",
       " 'favorite',\n",
       " 'superhero',\n",
       " 'movie',\n",
       " 'The',\n",
       " 'Dark',\n",
       " 'Knight',\n",
       " 'shows',\n",
       " 'the',\n",
       " 'potential',\n",
       " 'of',\n",
       " 'Batman',\n",
       " 'movie',\n",
       " 'The',\n",
       " 'film',\n",
       " 'has',\n",
       " 'some',\n",
       " 'flaws',\n",
       " 'but',\n",
       " 'those',\n",
       " 'are',\n",
       " 'easily',\n",
       " 'glossed',\n",
       " 'over',\n",
       " 'with',\n",
       " 'the',\n",
       " 'brilliant',\n",
       " 'performance',\n",
       " 'of',\n",
       " 'Heath',\n",
       " 'Ledger',\n",
       " 'as',\n",
       " 'the',\n",
       " 'Joker',\n",
       " 'for',\n",
       " 'which',\n",
       " 'he',\n",
       " 'won',\n",
       " 'an',\n",
       " 'Academy',\n",
       " 'Award',\n",
       " 'Christian',\n",
       " 'Bale',\n",
       " 'returns',\n",
       " 'to',\n",
       " 'play',\n",
       " 'the',\n",
       " 'Batman',\n",
       " 'and',\n",
       " 'though',\n",
       " 'this',\n",
       " 'movie',\n",
       " 'continues',\n",
       " 'the',\n",
       " 'story',\n",
       " 'that',\n",
       " 'started',\n",
       " 'with',\n",
       " 'Batman',\n",
       " 'Begins',\n",
       " 'it',\n",
       " 'feels',\n",
       " 'like',\n",
       " 'wholly',\n",
       " 'separate',\n",
       " 'film',\n",
       " 'that',\n",
       " 'stands',\n",
       " 'easily',\n",
       " 'on',\n",
       " 'its',\n",
       " 'own',\n",
       " 'The',\n",
       " 'movie',\n",
       " 'starts',\n",
       " 'with',\n",
       " 'very',\n",
       " 'cool',\n",
       " 'robbery',\n",
       " 'scene',\n",
       " 'remember',\n",
       " 'this',\n",
       " 'scene',\n",
       " 'being',\n",
       " 'released',\n",
       " 'early',\n",
       " 'to',\n",
       " 'build',\n",
       " 'excitement',\n",
       " 'and',\n",
       " 'watched',\n",
       " 'it',\n",
       " 'several',\n",
       " 'times',\n",
       " 'It',\n",
       " 'introduced',\n",
       " 'the',\n",
       " 'villain',\n",
       " 'in',\n",
       " 'very',\n",
       " 'cool',\n",
       " 'way',\n",
       " 'and',\n",
       " 'showed',\n",
       " 'his',\n",
       " 'craziness',\n",
       " 'from',\n",
       " 'his',\n",
       " 'first',\n",
       " 'reveal',\n",
       " 'The',\n",
       " 'story',\n",
       " 'of',\n",
       " 'Gotham',\n",
       " 'continues',\n",
       " 'in',\n",
       " 'the',\n",
       " 'wake',\n",
       " 'of',\n",
       " 'the',\n",
       " 'appearance',\n",
       " 'of',\n",
       " 'Batman',\n",
       " 'It',\n",
       " 'draws',\n",
       " 'from',\n",
       " 'the',\n",
       " 'phase',\n",
       " 'of',\n",
       " 'the',\n",
       " 'comics',\n",
       " 'that',\n",
       " 'am',\n",
       " 'more',\n",
       " 'familiar',\n",
       " 'with',\n",
       " 'in',\n",
       " 'that',\n",
       " 'Batman',\n",
       " 'has',\n",
       " 'been',\n",
       " 'practicing',\n",
       " 'his',\n",
       " 'crime',\n",
       " 'fighting',\n",
       " 'for',\n",
       " 'while',\n",
       " 'and',\n",
       " 'most',\n",
       " 'criminals',\n",
       " 'are',\n",
       " 'scared.Check',\n",
       " 'out',\n",
       " 'more',\n",
       " 'of',\n",
       " 'this',\n",
       " 'review',\n",
       " 'and',\n",
       " 'others',\n",
       " 'at',\n",
       " 'swilliky.com']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokenized[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "j_x3Tk2Eiin9",
    "outputId": "ae6a627b-299b-4e3e-a750-40f5a2ddc6ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 221 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight={1: 1.75}, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "w2v_lr = LogisticRegression(random_state=42, max_iter=1000, class_weight={1:1.75})\n",
    "w2v_lr.fit(X_train_word_average, train_data['is_spoiler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score: 72.3168 %\n",
      "Test accuracy score: 70.6914 %\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy score:', round(w2v_lr.score(X_train_word_average, train_data['is_spoiler'])*100,4),'%')\n",
    "print('Test accuracy score:', round(w2v_lr.score(X_test_word_average, test_data['is_spoiler'])*100,4),'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q9dbiMmiiisb"
   },
   "outputs": [],
   "source": [
    "w2v_predict = w2v_lr.predict(X_test_word_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 174
    },
    "colab_type": "code",
    "id": "Df4okphFjf3P",
    "outputId": "e3e50e0d-c1fa-4d15-a005-124d6e7d01f3",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 538\n",
      "False Negatives: 167\n",
      "False Positives: 117\n",
      "True Positives: 147\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>538</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>167</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Predicted Negative Predicted Positive\n",
       "Actual Negative                538                117\n",
       "Actual Positive                167                147"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_table(test_data['is_spoiler'], w2v_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec on top 10 movie reviews from the most popular genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_movies_genre = list(df['genre'].value_counts()[:1].index)\n",
    "many_movies_genre = df[df['genre'].isin(list_movies_genre)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_movies = list(many_movies_genre['movie_title'].value_counts()[0:10].index)\n",
    "many_movies = many_movies_genre[many_movies_genre['movie_title'].isin(list_movies)]\n",
    "many_movies = many_movies[['review','is_spoiler']]\n",
    "train_many, test_many = train_test_split(many_movies, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tokenized_many = train_many.apply(lambda r: w2v_tokenize_text(r['review']), axis=1).values\n",
    "test_tokenized_many = test_many.apply(lambda r: w2v_tokenize_text(r['review']), axis=1).values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7.94 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X_train_word_ave_many = word_averaging_list(wv,train_tokenized_many)\n",
    "X_test_word_ave_many = word_averaging_list(wv,test_tokenized_many)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 283 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight={1: 1.75}, dual=False,\n",
       "                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,\n",
       "                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=42, solver='lbfgs', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "w2v_many_lr = LogisticRegression(random_state=42, max_iter=1000, class_weight={1:1.75})\n",
    "w2v_many_lr.fit(X_train_word_ave_many, train_many['is_spoiler'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy score: 68.9907 %\n",
      "Test accuracy score: 67.8426 %\n"
     ]
    }
   ],
   "source": [
    "print('Train accuracy score:', round(w2v_many_lr.score(X_train_word_ave_many, train_many['is_spoiler'])*100,4),'%')\n",
    "print('Test accuracy score:', round(w2v_many_lr.score(X_test_word_ave_many, test_many['is_spoiler'])*100,4),'%')\n",
    "w2v_many_predict = w2v_many_lr.predict(X_test_word_ave_many)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 653\n",
      "False Negatives: 188\n",
      "False Positives: 286\n",
      "True Positives: 347\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>653</td>\n",
       "      <td>286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>188</td>\n",
       "      <td>347</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Predicted Negative Predicted Positive\n",
       "Actual Negative                653                286\n",
       "Actual Positive                188                347"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_table(test_many['is_spoiler'], w2v_many_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Doc2Vec on one movie's reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_sentences(corpus, label_type):\n",
    "    labeled = []\n",
    "    for i, v in enumerate(corpus):\n",
    "        label = label_type + '_' + str(i)\n",
    "        labeled.append(gensim.models.doc2vec.TaggedDocument(v.split(), [label]))\n",
    "    return labeled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vectors(model, corpus_size, vectors_size, vectors_type):\n",
    "    vectors = np.zeros((corpus_size, vectors_size))\n",
    "    for i in range(0, corpus_size):\n",
    "        prefix = vectors_type + '_' + str(i)\n",
    "        vectors[i] = model.docvecs[prefix]\n",
    "    return vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(one_movie['review'], one_movie['is_spoiler'], random_state=0, test_size=0.3)\n",
    "X_train = label_sentences(X_train, 'Train')\n",
    "X_test = label_sentences(X_test, 'Test')\n",
    "all_data = X_train + X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 1214595.83it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 2425567.30it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 4855771.30it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 808683.31it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 1619235.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 2434575.64it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 901810.73it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 2425856.86it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 2429627.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 374436.23it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 693894.79it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 1629492.65it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 5346330.67it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 4852292.95it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 972222.89it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 2428465.93it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 536312.13it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 2178771.62it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 809262.99it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 809908.05it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 1619106.28it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 971757.98it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 1618332.63it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 2428756.17it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 459593.88it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 2182281.24it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 2430208.43it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 2430789.82it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 2429046.48it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 2429627.32it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 4845/4845 [00:00<00:00, 809295.22it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=400, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow.build_vocab([x for x in tqdm(all_data)])\n",
    "\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(all_data)]), total_examples=len(all_data), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "   \n",
    "train_vectors_dbow = get_vectors(model_dbow, len(X_train), 400, 'Train')\n",
    "test_vectors_dbow = get_vectors(model_dbow, len(X_test), 400, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.6891334250343879\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.84      0.79      1012\n",
      "           1       0.48      0.35      0.40       442\n",
      "\n",
      "    accuracy                           0.69      1454\n",
      "   macro avg       0.62      0.59      0.60      1454\n",
      "weighted avg       0.67      0.69      0.67      1454\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(train_vectors_dbow, y_train)\n",
    "logreg = logreg.fit(train_vectors_dbow, y_train)\n",
    "y_pred = logreg.predict(test_vectors_dbow)\n",
    "print('accuracy %s' % accuracy_score(y_pred, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 849\n",
      "False Negatives: 289\n",
      "False Positives: 163\n",
      "True Positives: 153\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>849</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>289</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Predicted Negative Predicted Positive\n",
       "Actual Negative                849                163\n",
       "Actual Positive                289                153"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_table(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dov2Vec on top 10 movie reviews from the most popular genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_many_train = train_many['review']\n",
    "X_many_test = test_many['review']\n",
    "y_many_train = train_many['is_spoiler']\n",
    "y_many_test = test_many['is_spoiler']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_many_train = label_sentences(X_many_train, 'Train')\n",
    "X_many_test = label_sentences(X_many_test, 'Test')\n",
    "many_data = X_many_train + X_many_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 2463560.19it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 3692691.30it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 3694456.87it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 1477782.75it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 1231387.50it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 2463363.85it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 1231338.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 2461990.30it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 1847007.66it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 1847559.70it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 1847228.44it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 2462971.25it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 2463167.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 2124249.22it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 2462186.42it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 2462578.77it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 2461402.10it/s]\n",
      "100%|██████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 821012.22it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 3695340.29it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 2463167.53it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████| 7369/7369 [00:00<00:00, 1231632.84it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow_many = Doc2Vec(dm=0, vector_size=400, negative=5, min_count=1, alpha=0.065, min_alpha=0.065)\n",
    "model_dbow_many.build_vocab([x for x in tqdm(many_data)])\n",
    "\n",
    "for epoch in range(20):\n",
    "    model_dbow_many.train(utils.shuffle([x for x in tqdm(many_data)]), total_examples=len(many_data), epochs=1)\n",
    "    model_dbow_many.alpha -= 0.002\n",
    "    model_dbow_many.min_alpha = model_dbow_many.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vectors_dbow_many = get_vectors(model_dbow_many, len(X_many_train), 400, 'Train')\n",
    "test_vectors_dbow_many = get_vectors(model_dbow_many, len(X_many_test), 400, 'Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.7008141112618724\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.83      0.78       939\n",
      "           1       0.61      0.47      0.53       535\n",
      "\n",
      "    accuracy                           0.70      1474\n",
      "   macro avg       0.67      0.65      0.66      1474\n",
      "weighted avg       0.69      0.70      0.69      1474\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logreg_many = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg_many.fit(train_vectors_dbow_many, y_many_train)\n",
    "logreg_many = logreg_many.fit(train_vectors_dbow_many, y_many_train)\n",
    "y_pred_many = logreg_many.predict(test_vectors_dbow_many)\n",
    "print('accuracy %s' % accuracy_score(y_pred_many, y_many_test))\n",
    "print(classification_report(y_many_test, y_pred_many))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Negatives: 781\n",
      "False Negatives: 283\n",
      "False Positives: 158\n",
      "True Positives: 252\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Negative</th>\n",
       "      <th>Predicted Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual Negative</th>\n",
       "      <td>781</td>\n",
       "      <td>158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual Positive</th>\n",
       "      <td>283</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Predicted Negative Predicted Positive\n",
       "Actual Negative                781                158\n",
       "Actual Positive                283                252"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_table(y_many_test, y_pred_many)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Untitled1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
